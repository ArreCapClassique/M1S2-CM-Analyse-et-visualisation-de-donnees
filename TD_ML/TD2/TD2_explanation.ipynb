{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49a1028",
   "metadata": {},
   "source": [
    "A detailed explanation of [TD2_pipeline](TD2_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5aca77",
   "metadata": {},
   "source": [
    "# ğŸ“Š Analyse des Matrices de Confusion â€“ Random Forest\n",
    "\n",
    "## 1. ModÃ¨le avec **Toutes les variables (Full Features)**\n",
    "\n",
    "### ğŸ”¹ EntraÃ®nement :\n",
    "\n",
    "|                 | PrÃ©dit 0 | PrÃ©dit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| RÃ©el 0          | **88** (TN) | **61** (FP) |\n",
    "| RÃ©el 1          | **33** (FN) | **309** (TP) |\n",
    "\n",
    "- **88 vrais nÃ©gatifs (TN)** : bien classÃ©s comme 0.\n",
    "- **61 faux positifs (FP)** : classe 0 mal prÃ©dite en 1 â†’ tendance Ã  **surestimer la classe 1**.\n",
    "- **33 faux nÃ©gatifs (FN)** : classe 1 manquÃ©e.\n",
    "- **309 vrais positifs (TP)** : bien dÃ©tectÃ©s.\n",
    "\n",
    "> ğŸ“‰ **ProblÃ¨me :** taux Ã©levÃ© de faux positifs â†’ **modÃ¨le biaisÃ© vers la classe 1**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Test :\n",
    "\n",
    "|                 | PrÃ©dit 0 | PrÃ©dit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| RÃ©el 0          | **20** | **23** |\n",
    "| RÃ©el 1          | **11** | **69** |\n",
    "\n",
    "- Performance plus faible qu'en entraÃ®nement.\n",
    "- **11 faux nÃ©gatifs**, **23 faux positifs**.\n",
    "- Le modÃ¨le **gÃ©nÃ©ralise mal** : probable **sur-apprentissage**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ModÃ¨le avec **Variables sÃ©lectionnÃ©es (Selected Features)**\n",
    "\n",
    "### ğŸ”¹ EntraÃ®nement :\n",
    "\n",
    "|                 | PrÃ©dit 0 | PrÃ©dit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| RÃ©el 0          | **64** | **85** |\n",
    "| RÃ©el 1          | **6** | **336** |\n",
    "\n",
    "- **Seulement 6 faux nÃ©gatifs** â†’ excellent **rappel** de la classe 1.\n",
    "- **85 faux positifs** â†’ le modÃ¨le **sacrifie la prÃ©cision sur la classe 0**.\n",
    "- Le modÃ¨le **favorise trÃ¨s fortement la classe 1**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ Test :\n",
    "\n",
    "|                 | PrÃ©dit 0 | PrÃ©dit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| RÃ©el 0          | **18** | **25** |\n",
    "| RÃ©el 1          | **1** | **79** |\n",
    "\n",
    "- **1 seul faux nÃ©gatif** â†’ trÃ¨s forte capacitÃ© Ã  **dÃ©tecter la classe 1**.\n",
    "- **25 faux positifs** : baisse par rapport Ã  l'entraÃ®nement.\n",
    "- ModÃ¨le **stable, robuste, bonne gÃ©nÃ©ralisation**.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Comparaison finale\n",
    "\n",
    "| CritÃ¨re                        | Full Features                   | Selected Features               |\n",
    "|-------------------------------|----------------------------------|----------------------------------|\n",
    "| Rappel (classe 1)             | Bon (FN = 33)                    | Excellent (FN = 1)               |\n",
    "| PrÃ©cision (classe 0)          | Bonne                            | Faible (beaucoup de FP)          |\n",
    "| GÃ©nÃ©ralisation (test)         | Faible (overfitting)             | Excellente                       |\n",
    "| ComplexitÃ©                    | Ã‰levÃ©e (toutes variables)        | RÃ©duite (sÃ©lection de variables) |\n",
    "| Biais vers classe 1           | ModÃ©rÃ©                           | TrÃ¨s fort                        |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Recommandation mÃ©tier\n",
    "\n",
    "- Si la classe **1 reprÃ©sente un cas critique** (fraude, maladie, dÃ©faut), **le modÃ¨le avec variables sÃ©lectionnÃ©es est recommandÃ©** : il **manque trÃ¨s peu de cas importants**.\n",
    "- Si les **faux positifs sont coÃ»teux**, il faudrait **rÃ©ajuster le modÃ¨le** (ex. : en modifiant le seuil de dÃ©cision ou en rebalanÃ§ant les classes).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5dc7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34474c90",
   "metadata": {},
   "source": [
    "# ğŸ“‹ Rapport de Classification â€“ Comparaison entre Full Features et Selected Features\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”· 1. ModÃ¨le avec **Toutes les variables (Full Features)**\n",
    "\n",
    "### ğŸ”¹ Train\n",
    "\n",
    "| Classe | PrÃ©cision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.73      | 0.59   | 0.65     | 149     |\n",
    "| 1      | 0.84      | 0.90   | 0.87     | 342     |\n",
    "\n",
    "- **Classe 1 est mieux reconnue** que la classe 0.\n",
    "- **Rappel de classe 0 = 0.59** â†’ beaucoup de faux nÃ©gatifs.\n",
    "- **Rappel classe 1 Ã©levÃ© = 0.90** â†’ le modÃ¨le dÃ©tecte bien la classe 1.\n",
    "\n",
    "> ğŸ¯ Accuracy : **0.81**\n",
    "\n",
    "### ğŸ”¹ Test\n",
    "\n",
    "| Classe | PrÃ©cision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.65      | 0.47   | 0.54     | 43      |\n",
    "| 1      | 0.75      | 0.86   | 0.80     | 80      |\n",
    "\n",
    "- **Chute du rappel pour la classe 0 Ã  0.47** â†’ mauvaise gÃ©nÃ©ralisation.\n",
    "- **Classe 1 reste bien dÃ©tectÃ©e** (F1 = 0.80), mais performance globale dÃ©gradÃ©e.\n",
    "\n",
    "> ğŸ¯ Accuracy test : **0.72**\n",
    "\n",
    "> âš ï¸ Indices de **sur-apprentissage (overfitting)**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”· 2. ModÃ¨le avec **Variables sÃ©lectionnÃ©es (Selected Features)**\n",
    "\n",
    "### ğŸ”¹ Train\n",
    "\n",
    "| Classe | PrÃ©cision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.91      | 0.43   | 0.58     | 149     |\n",
    "| 1      | 0.80      | 0.98   | 0.88     | 342     |\n",
    "\n",
    "- Le modÃ¨le **sacrifie le rappel sur la classe 0 (0.43)** pour obtenir un **rappel quasi parfait sur la classe 1 (0.98)**.\n",
    "- TrÃ¨s **fort biais vers la classe 1**, ce qui peut Ãªtre justifiÃ© si câ€™est la classe critique.\n",
    "\n",
    "> ğŸ¯ Accuracy : **0.81**\n",
    "\n",
    "### ğŸ”¹ Test\n",
    "\n",
    "| Classe | PrÃ©cision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.95      | 0.42   | 0.58     | 43      |\n",
    "| 1      | 0.76      | 0.99   | 0.86     | 80      |\n",
    "\n",
    "- **Classe 1** : excellente performance (rappel 0.99, F1 = 0.86)\n",
    "- **Classe 0** : rappel toujours trÃ¨s faible (0.42) malgrÃ© une **prÃ©cision trÃ¨s haute (0.95)** â†’ le modÃ¨le ne prÃ©dit la classe 0 **que quand il est sÃ»r**, mais **rarement**.\n",
    "\n",
    "> ğŸ¯ Accuracy test : **0.79**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Comparaison globale\n",
    "\n",
    "| CritÃ¨re             | Full Features       | Selected Features     |\n",
    "|---------------------|---------------------|------------------------|\n",
    "| F1-score (Classe 1) | 0.80 (test)         | **0.86 (test)**        |\n",
    "| Rappel (Classe 1)   | 0.86 (test)         | **0.99 (test)**        |\n",
    "| Rappel (Classe 0)   | **0.47 (test)**     | 0.42 (test)            |\n",
    "| PrÃ©cision (Classe 0)| 0.65                | **0.95**               |\n",
    "| Accuracy (test)     | 0.72                | **0.79**               |\n",
    "| GÃ©nÃ©ralisation      | Moyenne             | Bonne                  |\n",
    "| Biais de classe     | ModÃ©rÃ©              | Fortement vers classe 1|\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Conclusion mÃ©tier\n",
    "\n",
    "- **Si la classe 1 est critique (ex. fraude, maladie, dÃ©faut)** :\n",
    "  - â†’ Le **modÃ¨le avec variables sÃ©lectionnÃ©es est prÃ©fÃ©rable**.\n",
    "  - Il **manque trÃ¨s peu de cas positifs** (rappel = 0.99), ce qui est souvent **prioritaire** en contexte sensible.\n",
    "\n",
    "- **Mais si les faux positifs coÃ»tent cher (erreurs sur classe 0)** :\n",
    "  - Il faudra **ajuster le seuil** de dÃ©cision ou rÃ©Ã©quilibrer la prÃ©cision/rappel.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd05a2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b0af32",
   "metadata": {},
   "source": [
    "# ğŸ“‰ Comment mesurer une \"grande chute\" de performance entre l'entraÃ®nement et le test ?\n",
    "\n",
    "Il nâ€™existe **pas de seuil absolu universel**, mais certains **critÃ¨res empiriques** permettent de juger si une baisse de performance entre les donnÃ©es d'entraÃ®nement et de test est significative et signe d'un **surapprentissage (overfitting)**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ” RÃ¨gles pratiques pour juger l'importance d'une chute\n",
    "\n",
    "| Type de chute                | Ampleur approximative         | InterprÃ©tation                               |\n",
    "|-----------------------------|-------------------------------|-----------------------------------------------|\n",
    "| **Faible**                  | < 5 points de pourcentage     | GÃ©nÃ©ralisation correcte, pas dâ€™inquiÃ©tude.    |\n",
    "| **ModÃ©rÃ©e**                 | 5â€“10 points                   | Surapprentissage possible, Ã  surveiller.      |\n",
    "| **Importante**              | > 10â€“15 points                | Probable surapprentissage.                    |\n",
    "| **TrÃ¨s importante / critique** | > 20 points               | Surapprentissage fort, ou fuite de donnÃ©es.   |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ Exemple concret\n",
    "\n",
    "- **F1-score** :\n",
    "  - EntraÃ®nement : `0.91`\n",
    "  - Test : `0.76`\n",
    "  - âœ **Chute de 15 points** â†’ surapprentissage **important**\n",
    "  \n",
    "- **Accuracy** :\n",
    "  - EntraÃ®nement : `0.82`\n",
    "  - Test : `0.78`\n",
    "  - âœ **Chute de 4 points** â†’ **acceptable**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Autres facteurs Ã  prendre en compte\n",
    "\n",
    "- **Taille de lâ€™Ã©chantillon** : les petits jeux de donnÃ©es entraÃ®nent plus de variance.\n",
    "- **ComplexitÃ© du modÃ¨le** : les modÃ¨les trÃ¨s flexibles (forÃªts profondes, rÃ©seaux neuronaux) surajustent plus facilement.\n",
    "- **DÃ©sÃ©quilibre des classes** : peut fausser les scores de prÃ©cision ou de rappel.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Recommandation\n",
    "\n",
    "Comparer les mÃ©triques (accuracy, recall, f1-score...) entre entraÃ®nement et test. Si la chute dÃ©passe **10 points**, envisagez :\n",
    "- simplification du modÃ¨le,\n",
    "- ajout de rÃ©gularisation,\n",
    "- plus de donnÃ©es,\n",
    "- ou arrÃªt anticipÃ© (early stopping).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92316f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9329876a",
   "metadata": {},
   "source": [
    "# ğŸ“ˆ Analyse des Graphiques SHAP â€“ InterprÃ©tabilitÃ© du modÃ¨le Random Forest\n",
    "\n",
    "Les graphiques suivants reprÃ©sentent les **valeurs SHAP** du modÃ¨le Random Forest entraÃ®nÃ© sur le jeu de donnÃ©es avec **toutes les variables (full features)**.\n",
    "\n",
    "Chaque point correspond Ã  une prÃ©diction individuelle. Lâ€™axe horizontal montre lâ€™impact dâ€™une variable sur la prÃ©diction finale : plus la valeur SHAP est Ã©loignÃ©e de 0, plus la variable influence fortement la dÃ©cision.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”· 1. **SHAP sur les donnÃ©es dâ€™entraÃ®nement (`Train`)**\n",
    "\n",
    "### ğŸ”¹ Principaux enseignements :\n",
    "\n",
    "- **`Credit_History`** est de loin la variable **la plus dÃ©terminante** : les faibles valeurs (bleu) tendent Ã  **faire baisser** la probabilitÃ© de recevoir un crÃ©dit (valeurs SHAP fortement nÃ©gatives).\n",
    "- Les variables **`Married`, `LoanAmount`, `Property_Area`, `CoapplicantIncome`, `ApplicantIncome`** ont aussi un **impact non nÃ©gligeable**, mais leur influence reste **modÃ©rÃ©e** (valeurs SHAP proches de 0).\n",
    "- Les variables comme **`Education`, `Gender`, `Self_Employed`** ont **trÃ¨s peu dâ€™impact** sur la prÃ©diction.\n",
    "\n",
    "### ğŸ”¹ InterprÃ©tation couleur :\n",
    "\n",
    "- En rouge : valeurs **Ã©levÃ©es** de la variable.\n",
    "- En bleu : valeurs **faibles**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”· 2. **SHAP sur les donnÃ©es de test (`Test`)**\n",
    "\n",
    "### ğŸ”¹ Principaux constats :\n",
    "\n",
    "- On retrouve le **mÃªme ordre dâ€™importance** que dans le jeu dâ€™entraÃ®nement : `Credit_History` reste **dominant**.\n",
    "- Les variables influentes sont **cohÃ©rentes avec lâ€™entraÃ®nement**, ce qui **confirme la stabilitÃ© du modÃ¨le**.\n",
    "- Les valeurs SHAP de `Credit_History` sur les donnÃ©es de test vont Ã©galement fortement vers la gauche pour des valeurs faibles, ce qui signifie une **rÃ©duction nette de la probabilitÃ© dâ€™octroi**.\n",
    "\n",
    "### ğŸ”¹ Autres remarques :\n",
    "\n",
    "- `LoanAmount`, `Married`, `Property_Area`, et `CoapplicantIncome` montrent des **effets directionnels similaires** Ã  ceux observÃ©s en entraÃ®nement.\n",
    "- Cela suggÃ¨re que le modÃ¨le **gÃ©nÃ©ralise bien** et quâ€™aucune variable ne change drastiquement de rÃ´le entre entraÃ®nement et test.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Conclusion\n",
    "\n",
    "| Ã‰lÃ©ment clÃ©            | InterprÃ©tation                                                                 |\n",
    "|------------------------|--------------------------------------------------------------------------------|\n",
    "| Variable la plus forte | `Credit_History` (impact massif, direction claire)                            |\n",
    "| Variables secondaires  | `LoanAmount`, `Married`, `CoapplicantIncome`, `Property_Area`, `ApplicantIncome` |\n",
    "| Variables faibles      | `Self_Employed`, `Gender`, `Education` (impact presque nul)                   |\n",
    "| CohÃ©rence Train/Test   | Oui â€“ les variables conservent leur importance et influence                   |\n",
    "\n",
    "ğŸ” Les SHAP values confirment que le modÃ¨le est **interprÃ©table, stable et centrÃ© sur lâ€™historique de crÃ©dit** comme facteur dÃ©terminant de dÃ©cision.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29736eb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5376c571",
   "metadata": {},
   "source": [
    "# ğŸ“Š InterprÃ©tation des Graphiques ICE / PDP â€“ ModÃ¨le Random Forest\n",
    "\n",
    "Ces graphiques montrent, pour chaque variable, comment la probabilitÃ© de prÃ©diction du modÃ¨le varie **lorsqu'on modifie uniquement cette variable**, en gardant les autres constantes. Chaque ligne bleue pÃ¢le correspond Ã  une prÃ©diction individuelle (ICE), et la courbe bleue Ã©paisse reprÃ©sente la moyenne de toutes (PDP).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 1. `ApplicantIncome`\n",
    "\n",
    "- Lorsque le revenu du demandeur augmente, l'effet sur la prÃ©diction est **quasiment neutre** aprÃ¨s un certain seuil.\n",
    "- **Autour de la valeur 0**, il y a un lÃ©ger pic, puis une stabilisation.\n",
    "- Cela signifie que le modÃ¨le **nâ€™est pas trÃ¨s sensible** Ã  cette variable aprÃ¨s un certain niveau de revenu.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 2. `CoapplicantIncome`\n",
    "\n",
    "- Un comportement similaire Ã  `ApplicantIncome`.\n",
    "- Une **lÃ©gÃ¨re hausse de prÃ©diction autour de 0**, puis un effet plat.\n",
    "- Le revenu du co-demandeur **influence lÃ©gÃ¨rement la prÃ©diction**, mais son effet est trÃ¨s localisÃ©.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 3. `LoanAmount`\n",
    "\n",
    "- Plus le montant du prÃªt augmente, plus la probabilitÃ© de prÃ©diction **diminue lÃ©gÃ¨rement**.\n",
    "- Cela est **logique Ã©conomiquement** : des prÃªts plus Ã©levÃ©s peuvent Ãªtre associÃ©s Ã  un risque accru.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 4. `Loan_Amount_Term`\n",
    "\n",
    "- Graphique **discret** (car la variable est probablement catÃ©gorique ou binaire).\n",
    "- On observe des sauts nets de probabilitÃ© en fonction de la valeur.\n",
    "- **Certaines durÃ©es de prÃªt** augmentent lÃ©gÃ¨rement la probabilitÃ© de prÃ©diction.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 5. `Gender`\n",
    "\n",
    "- Le modÃ¨le ne semble **pas affectÃ© par le genre**.\n",
    "- La courbe est plate, ce qui est un bon signe dâ€™**Ã©quitÃ© algorithmique**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 6. `Married`\n",
    "\n",
    "- ÃŠtre mariÃ©(e) augmente lÃ©gÃ¨rement la probabilitÃ© dâ€™octroi (petit saut vers le haut Ã  1).\n",
    "- Cela pourrait reflÃ©ter une **meilleure stabilitÃ© financiÃ¨re perÃ§ue** par le modÃ¨le.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 7. `Dependents`\n",
    "\n",
    "- La courbe monte lÃ©gÃ¨rement avec le nombre de personnes Ã  charge.\n",
    "- Cela pourrait indiquer que certaines valeurs sont **associÃ©es Ã  de meilleurs profils** dans les donnÃ©es (ex. : familles stables ?).\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 8. `Education`\n",
    "\n",
    "- Aucune variation significative entre les deux modalitÃ©s.\n",
    "- Le modÃ¨le **nâ€™utilise pas vraiment cette variable** pour ajuster ses prÃ©dictions.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 9. `Self_Employed`\n",
    "\n",
    "- Les personnes **non salariÃ©es** n'ont pas un impact net sur la prÃ©diction.\n",
    "- La courbe reste plate â†’ **peu dâ€™influence sur le modÃ¨le**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 10. `Credit_History` âœ…\n",
    "\n",
    "- Variable **la plus influente**.\n",
    "- Passage de `0` Ã  `1` provoque une **forte augmentation de la probabilitÃ© de crÃ©dit acceptÃ©**.\n",
    "- Confirme les observations SHAP : **lâ€™historique de crÃ©dit est dÃ©terminant** dans la dÃ©cision.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 11. `Property_Area`\n",
    "\n",
    "- Variable catÃ©gorique avec 3 modalitÃ©s (0 = rural, 1 = semi-urbain, 2 = urbain par exemple).\n",
    "- **La zone semi-urbaine (1)** montre une **probabilitÃ© plus Ã©levÃ©e dâ€™approbation** que les deux autres.\n",
    "- Les zones rurales et urbaines ont une probabilitÃ© plus faible et Ã©quivalente.\n",
    "- Cela suggÃ¨re que les **clients vivant en zone semi-urbaine** sont perÃ§us comme **moins risquÃ©s** par le modÃ¨le.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Conclusion gÃ©nÃ©rale\n",
    "\n",
    "| Variable             | Impact sur la prÃ©diction              | Commentaire                        |\n",
    "|----------------------|----------------------------------------|-------------------------------------|\n",
    "| `Credit_History`     | â­ TrÃ¨s fort                           | Variable critique                   |\n",
    "| `LoanAmount`         | Moyen (nÃ©gatif)                       | Plus le prÃªt est Ã©levÃ©, moins Ã§a passe |\n",
    "| `Property_Area`      | Moyen (zone semi-urbaine favorisÃ©e)   | Influence claire                    |\n",
    "| `Married`            | LÃ©ger impact positif                  | Profil plus fiable ?                |\n",
    "| `ApplicantIncome`    | Faible Ã  moyen                        | Seulement autour de 0               |\n",
    "| `CoapplicantIncome`  | Faible                                | Localement positif                  |\n",
    "| `Loan_Amount_Term`   | Discret, faible impact                | DÃ©pend des valeurs exactes          |\n",
    "| `Dependents`         | LÃ©ger effet croissant                 | Possiblement liÃ© Ã  stabilitÃ©        |\n",
    "| `Gender`, `Education`, `Self_Employed` | Quasi nul        | Le modÃ¨le les ignore pratiquement   |\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ¯ Les PDP/ICE complÃ¨tent bien lâ€™analyse SHAP en confirmant quelles variables ont un **effet causal visible et directionnel** sur les prÃ©dictions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
