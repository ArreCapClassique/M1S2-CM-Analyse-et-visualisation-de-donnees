{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49a1028",
   "metadata": {},
   "source": [
    "A detailed explanation of [TD2_pipeline](TD2_pipeline.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5aca77",
   "metadata": {},
   "source": [
    "# 📊 Analyse des Matrices de Confusion – Random Forest\n",
    "\n",
    "## 1. Modèle avec **Toutes les variables (Full Features)**\n",
    "\n",
    "### 🔹 Entraînement :\n",
    "\n",
    "|                 | Prédit 0 | Prédit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| Réel 0          | **88** (TN) | **61** (FP) |\n",
    "| Réel 1          | **33** (FN) | **309** (TP) |\n",
    "\n",
    "- **88 vrais négatifs (TN)** : bien classés comme 0.\n",
    "- **61 faux positifs (FP)** : classe 0 mal prédite en 1 → tendance à **surestimer la classe 1**.\n",
    "- **33 faux négatifs (FN)** : classe 1 manquée.\n",
    "- **309 vrais positifs (TP)** : bien détectés.\n",
    "\n",
    "> 📉 **Problème :** taux élevé de faux positifs → **modèle biaisé vers la classe 1**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Test :\n",
    "\n",
    "|                 | Prédit 0 | Prédit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| Réel 0          | **20** | **23** |\n",
    "| Réel 1          | **11** | **69** |\n",
    "\n",
    "- Performance plus faible qu'en entraînement.\n",
    "- **11 faux négatifs**, **23 faux positifs**.\n",
    "- Le modèle **généralise mal** : probable **sur-apprentissage**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Modèle avec **Variables sélectionnées (Selected Features)**\n",
    "\n",
    "### 🔹 Entraînement :\n",
    "\n",
    "|                 | Prédit 0 | Prédit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| Réel 0          | **64** | **85** |\n",
    "| Réel 1          | **6** | **336** |\n",
    "\n",
    "- **Seulement 6 faux négatifs** → excellent **rappel** de la classe 1.\n",
    "- **85 faux positifs** → le modèle **sacrifie la précision sur la classe 0**.\n",
    "- Le modèle **favorise très fortement la classe 1**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 Test :\n",
    "\n",
    "|                 | Prédit 0 | Prédit 1 |\n",
    "|-----------------|----------|----------|\n",
    "| Réel 0          | **18** | **25** |\n",
    "| Réel 1          | **1** | **79** |\n",
    "\n",
    "- **1 seul faux négatif** → très forte capacité à **détecter la classe 1**.\n",
    "- **25 faux positifs** : baisse par rapport à l'entraînement.\n",
    "- Modèle **stable, robuste, bonne généralisation**.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Comparaison finale\n",
    "\n",
    "| Critère                        | Full Features                   | Selected Features               |\n",
    "|-------------------------------|----------------------------------|----------------------------------|\n",
    "| Rappel (classe 1)             | Bon (FN = 33)                    | Excellent (FN = 1)               |\n",
    "| Précision (classe 0)          | Bonne                            | Faible (beaucoup de FP)          |\n",
    "| Généralisation (test)         | Faible (overfitting)             | Excellente                       |\n",
    "| Complexité                    | Élevée (toutes variables)        | Réduite (sélection de variables) |\n",
    "| Biais vers classe 1           | Modéré                           | Très fort                        |\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Recommandation métier\n",
    "\n",
    "- Si la classe **1 représente un cas critique** (fraude, maladie, défaut), **le modèle avec variables sélectionnées est recommandé** : il **manque très peu de cas importants**.\n",
    "- Si les **faux positifs sont coûteux**, il faudrait **réajuster le modèle** (ex. : en modifiant le seuil de décision ou en rebalançant les classes).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc5dc7a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34474c90",
   "metadata": {},
   "source": [
    "# 📋 Rapport de Classification – Comparaison entre Full Features et Selected Features\n",
    "\n",
    "---\n",
    "\n",
    "## 🔷 1. Modèle avec **Toutes les variables (Full Features)**\n",
    "\n",
    "### 🔹 Train\n",
    "\n",
    "| Classe | Précision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.73      | 0.59   | 0.65     | 149     |\n",
    "| 1      | 0.84      | 0.90   | 0.87     | 342     |\n",
    "\n",
    "- **Classe 1 est mieux reconnue** que la classe 0.\n",
    "- **Rappel de classe 0 = 0.59** → beaucoup de faux négatifs.\n",
    "- **Rappel classe 1 élevé = 0.90** → le modèle détecte bien la classe 1.\n",
    "\n",
    "> 🎯 Accuracy : **0.81**\n",
    "\n",
    "### 🔹 Test\n",
    "\n",
    "| Classe | Précision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.65      | 0.47   | 0.54     | 43      |\n",
    "| 1      | 0.75      | 0.86   | 0.80     | 80      |\n",
    "\n",
    "- **Chute du rappel pour la classe 0 à 0.47** → mauvaise généralisation.\n",
    "- **Classe 1 reste bien détectée** (F1 = 0.80), mais performance globale dégradée.\n",
    "\n",
    "> 🎯 Accuracy test : **0.72**\n",
    "\n",
    "> ⚠️ Indices de **sur-apprentissage (overfitting)**\n",
    "\n",
    "---\n",
    "\n",
    "## 🔷 2. Modèle avec **Variables sélectionnées (Selected Features)**\n",
    "\n",
    "### 🔹 Train\n",
    "\n",
    "| Classe | Précision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.91      | 0.43   | 0.58     | 149     |\n",
    "| 1      | 0.80      | 0.98   | 0.88     | 342     |\n",
    "\n",
    "- Le modèle **sacrifie le rappel sur la classe 0 (0.43)** pour obtenir un **rappel quasi parfait sur la classe 1 (0.98)**.\n",
    "- Très **fort biais vers la classe 1**, ce qui peut être justifié si c’est la classe critique.\n",
    "\n",
    "> 🎯 Accuracy : **0.81**\n",
    "\n",
    "### 🔹 Test\n",
    "\n",
    "| Classe | Précision | Rappel | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.95      | 0.42   | 0.58     | 43      |\n",
    "| 1      | 0.76      | 0.99   | 0.86     | 80      |\n",
    "\n",
    "- **Classe 1** : excellente performance (rappel 0.99, F1 = 0.86)\n",
    "- **Classe 0** : rappel toujours très faible (0.42) malgré une **précision très haute (0.95)** → le modèle ne prédit la classe 0 **que quand il est sûr**, mais **rarement**.\n",
    "\n",
    "> 🎯 Accuracy test : **0.79**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Comparaison globale\n",
    "\n",
    "| Critère             | Full Features       | Selected Features     |\n",
    "|---------------------|---------------------|------------------------|\n",
    "| F1-score (Classe 1) | 0.80 (test)         | **0.86 (test)**        |\n",
    "| Rappel (Classe 1)   | 0.86 (test)         | **0.99 (test)**        |\n",
    "| Rappel (Classe 0)   | **0.47 (test)**     | 0.42 (test)            |\n",
    "| Précision (Classe 0)| 0.65                | **0.95**               |\n",
    "| Accuracy (test)     | 0.72                | **0.79**               |\n",
    "| Généralisation      | Moyenne             | Bonne                  |\n",
    "| Biais de classe     | Modéré              | Fortement vers classe 1|\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Conclusion métier\n",
    "\n",
    "- **Si la classe 1 est critique (ex. fraude, maladie, défaut)** :\n",
    "  - → Le **modèle avec variables sélectionnées est préférable**.\n",
    "  - Il **manque très peu de cas positifs** (rappel = 0.99), ce qui est souvent **prioritaire** en contexte sensible.\n",
    "\n",
    "- **Mais si les faux positifs coûtent cher (erreurs sur classe 0)** :\n",
    "  - Il faudra **ajuster le seuil** de décision ou rééquilibrer la précision/rappel.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd05a2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b0af32",
   "metadata": {},
   "source": [
    "# 📉 Comment mesurer une \"grande chute\" de performance entre l'entraînement et le test ?\n",
    "\n",
    "Il n’existe **pas de seuil absolu universel**, mais certains **critères empiriques** permettent de juger si une baisse de performance entre les données d'entraînement et de test est significative et signe d'un **surapprentissage (overfitting)**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Règles pratiques pour juger l'importance d'une chute\n",
    "\n",
    "| Type de chute                | Ampleur approximative         | Interprétation                               |\n",
    "|-----------------------------|-------------------------------|-----------------------------------------------|\n",
    "| **Faible**                  | < 5 points de pourcentage     | Généralisation correcte, pas d’inquiétude.    |\n",
    "| **Modérée**                 | 5–10 points                   | Surapprentissage possible, à surveiller.      |\n",
    "| **Importante**              | > 10–15 points                | Probable surapprentissage.                    |\n",
    "| **Très importante / critique** | > 20 points               | Surapprentissage fort, ou fuite de données.   |\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Exemple concret\n",
    "\n",
    "- **F1-score** :\n",
    "  - Entraînement : `0.91`\n",
    "  - Test : `0.76`\n",
    "  - ➜ **Chute de 15 points** → surapprentissage **important**\n",
    "  \n",
    "- **Accuracy** :\n",
    "  - Entraînement : `0.82`\n",
    "  - Test : `0.78`\n",
    "  - ➜ **Chute de 4 points** → **acceptable**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 Autres facteurs à prendre en compte\n",
    "\n",
    "- **Taille de l’échantillon** : les petits jeux de données entraînent plus de variance.\n",
    "- **Complexité du modèle** : les modèles très flexibles (forêts profondes, réseaux neuronaux) surajustent plus facilement.\n",
    "- **Déséquilibre des classes** : peut fausser les scores de précision ou de rappel.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Recommandation\n",
    "\n",
    "Comparer les métriques (accuracy, recall, f1-score...) entre entraînement et test. Si la chute dépasse **10 points**, envisagez :\n",
    "- simplification du modèle,\n",
    "- ajout de régularisation,\n",
    "- plus de données,\n",
    "- ou arrêt anticipé (early stopping).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92316f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9329876a",
   "metadata": {},
   "source": [
    "# 📈 Analyse des Graphiques SHAP – Interprétabilité du modèle Random Forest\n",
    "\n",
    "Les graphiques suivants représentent les **valeurs SHAP** du modèle Random Forest entraîné sur le jeu de données avec **toutes les variables (full features)**.\n",
    "\n",
    "Chaque point correspond à une prédiction individuelle. L’axe horizontal montre l’impact d’une variable sur la prédiction finale : plus la valeur SHAP est éloignée de 0, plus la variable influence fortement la décision.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔷 1. **SHAP sur les données d’entraînement (`Train`)**\n",
    "\n",
    "### 🔹 Principaux enseignements :\n",
    "\n",
    "- **`Credit_History`** est de loin la variable **la plus déterminante** : les faibles valeurs (bleu) tendent à **faire baisser** la probabilité de recevoir un crédit (valeurs SHAP fortement négatives).\n",
    "- Les variables **`Married`, `LoanAmount`, `Property_Area`, `CoapplicantIncome`, `ApplicantIncome`** ont aussi un **impact non négligeable**, mais leur influence reste **modérée** (valeurs SHAP proches de 0).\n",
    "- Les variables comme **`Education`, `Gender`, `Self_Employed`** ont **très peu d’impact** sur la prédiction.\n",
    "\n",
    "### 🔹 Interprétation couleur :\n",
    "\n",
    "- En rouge : valeurs **élevées** de la variable.\n",
    "- En bleu : valeurs **faibles**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔷 2. **SHAP sur les données de test (`Test`)**\n",
    "\n",
    "### 🔹 Principaux constats :\n",
    "\n",
    "- On retrouve le **même ordre d’importance** que dans le jeu d’entraînement : `Credit_History` reste **dominant**.\n",
    "- Les variables influentes sont **cohérentes avec l’entraînement**, ce qui **confirme la stabilité du modèle**.\n",
    "- Les valeurs SHAP de `Credit_History` sur les données de test vont également fortement vers la gauche pour des valeurs faibles, ce qui signifie une **réduction nette de la probabilité d’octroi**.\n",
    "\n",
    "### 🔹 Autres remarques :\n",
    "\n",
    "- `LoanAmount`, `Married`, `Property_Area`, et `CoapplicantIncome` montrent des **effets directionnels similaires** à ceux observés en entraînement.\n",
    "- Cela suggère que le modèle **généralise bien** et qu’aucune variable ne change drastiquement de rôle entre entraînement et test.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Conclusion\n",
    "\n",
    "| Élément clé            | Interprétation                                                                 |\n",
    "|------------------------|--------------------------------------------------------------------------------|\n",
    "| Variable la plus forte | `Credit_History` (impact massif, direction claire)                            |\n",
    "| Variables secondaires  | `LoanAmount`, `Married`, `CoapplicantIncome`, `Property_Area`, `ApplicantIncome` |\n",
    "| Variables faibles      | `Self_Employed`, `Gender`, `Education` (impact presque nul)                   |\n",
    "| Cohérence Train/Test   | Oui – les variables conservent leur importance et influence                   |\n",
    "\n",
    "🔍 Les SHAP values confirment que le modèle est **interprétable, stable et centré sur l’historique de crédit** comme facteur déterminant de décision.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29736eb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5376c571",
   "metadata": {},
   "source": [
    "# 📊 Interprétation des Graphiques ICE / PDP – Modèle Random Forest\n",
    "\n",
    "Ces graphiques montrent, pour chaque variable, comment la probabilité de prédiction du modèle varie **lorsqu'on modifie uniquement cette variable**, en gardant les autres constantes. Chaque ligne bleue pâle correspond à une prédiction individuelle (ICE), et la courbe bleue épaisse représente la moyenne de toutes (PDP).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 1. `ApplicantIncome`\n",
    "\n",
    "- Lorsque le revenu du demandeur augmente, l'effet sur la prédiction est **quasiment neutre** après un certain seuil.\n",
    "- **Autour de la valeur 0**, il y a un léger pic, puis une stabilisation.\n",
    "- Cela signifie que le modèle **n’est pas très sensible** à cette variable après un certain niveau de revenu.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 2. `CoapplicantIncome`\n",
    "\n",
    "- Un comportement similaire à `ApplicantIncome`.\n",
    "- Une **légère hausse de prédiction autour de 0**, puis un effet plat.\n",
    "- Le revenu du co-demandeur **influence légèrement la prédiction**, mais son effet est très localisé.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 3. `LoanAmount`\n",
    "\n",
    "- Plus le montant du prêt augmente, plus la probabilité de prédiction **diminue légèrement**.\n",
    "- Cela est **logique économiquement** : des prêts plus élevés peuvent être associés à un risque accru.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 4. `Loan_Amount_Term`\n",
    "\n",
    "- Graphique **discret** (car la variable est probablement catégorique ou binaire).\n",
    "- On observe des sauts nets de probabilité en fonction de la valeur.\n",
    "- **Certaines durées de prêt** augmentent légèrement la probabilité de prédiction.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 5. `Gender`\n",
    "\n",
    "- Le modèle ne semble **pas affecté par le genre**.\n",
    "- La courbe est plate, ce qui est un bon signe d’**équité algorithmique**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 6. `Married`\n",
    "\n",
    "- Être marié(e) augmente légèrement la probabilité d’octroi (petit saut vers le haut à 1).\n",
    "- Cela pourrait refléter une **meilleure stabilité financière perçue** par le modèle.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 7. `Dependents`\n",
    "\n",
    "- La courbe monte légèrement avec le nombre de personnes à charge.\n",
    "- Cela pourrait indiquer que certaines valeurs sont **associées à de meilleurs profils** dans les données (ex. : familles stables ?).\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 8. `Education`\n",
    "\n",
    "- Aucune variation significative entre les deux modalités.\n",
    "- Le modèle **n’utilise pas vraiment cette variable** pour ajuster ses prédictions.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 9. `Self_Employed`\n",
    "\n",
    "- Les personnes **non salariées** n'ont pas un impact net sur la prédiction.\n",
    "- La courbe reste plate → **peu d’influence sur le modèle**.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 10. `Credit_History` ✅\n",
    "\n",
    "- Variable **la plus influente**.\n",
    "- Passage de `0` à `1` provoque une **forte augmentation de la probabilité de crédit accepté**.\n",
    "- Confirme les observations SHAP : **l’historique de crédit est déterminant** dans la décision.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔹 11. `Property_Area`\n",
    "\n",
    "- Variable catégorique avec 3 modalités (0 = rural, 1 = semi-urbain, 2 = urbain par exemple).\n",
    "- **La zone semi-urbaine (1)** montre une **probabilité plus élevée d’approbation** que les deux autres.\n",
    "- Les zones rurales et urbaines ont une probabilité plus faible et équivalente.\n",
    "- Cela suggère que les **clients vivant en zone semi-urbaine** sont perçus comme **moins risqués** par le modèle.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Conclusion générale\n",
    "\n",
    "| Variable             | Impact sur la prédiction              | Commentaire                        |\n",
    "|----------------------|----------------------------------------|-------------------------------------|\n",
    "| `Credit_History`     | ⭐ Très fort                           | Variable critique                   |\n",
    "| `LoanAmount`         | Moyen (négatif)                       | Plus le prêt est élevé, moins ça passe |\n",
    "| `Property_Area`      | Moyen (zone semi-urbaine favorisée)   | Influence claire                    |\n",
    "| `Married`            | Léger impact positif                  | Profil plus fiable ?                |\n",
    "| `ApplicantIncome`    | Faible à moyen                        | Seulement autour de 0               |\n",
    "| `CoapplicantIncome`  | Faible                                | Localement positif                  |\n",
    "| `Loan_Amount_Term`   | Discret, faible impact                | Dépend des valeurs exactes          |\n",
    "| `Dependents`         | Léger effet croissant                 | Possiblement lié à stabilité        |\n",
    "| `Gender`, `Education`, `Self_Employed` | Quasi nul        | Le modèle les ignore pratiquement   |\n",
    "\n",
    "---\n",
    "\n",
    "🎯 Les PDP/ICE complètent bien l’analyse SHAP en confirmant quelles variables ont un **effet causal visible et directionnel** sur les prédictions.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
